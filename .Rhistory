View(theta.estim)
theta.estim %>% group_by(id, tseg) %>% tally()
View(obs)
# nobs<- purrr::map_dfr(dat.list, obs.per.tseg)  #calc obs per tseg
nobs<- data.frame(id = obs$id, tseg = obs$tseg, n = apply(obs[,11:16], 1, sum))
#Create augmented matrix by replicating rows (tsegs) according to obs per tseg
theta.estim2<- aug_behav_df(dat = dat, theta.estim = theta.estim, nobs = nobs)
for (i in 1:nrow(theta.estim)) {
print(i)
ind<- which(dat$id == theta.estim$id[i] & dat$tseg == theta.estim$tseg[i])
if (i == 1) {
theta.estim2<- rep(theta.estim[i,], nobs$n[i]) %>%
unlist() %>%
matrix(nrow = nobs$n[i], ncol = ncol(theta.estim), byrow = TRUE)
} else {
tmp<- rep(theta.estim[i,], nobs$n[i]) %>%
unlist() %>%
matrix(nrow = nobs$n[i], ncol = ncol(theta.estim), byrow = TRUE)
theta.estim2<- rbind(theta.estim2, tmp)
}
}
View(nobs)
dat %>% filter(id==12) %>% filter(tseg==8)
dat %>% filter(id==12) %>% unique(tseg)
dat %>% filter(id==12) %>% unique(.$tseg)
dat[dat$id==12,"tseg"] %>% unique()
View(obs)
#get data
dat<- read.csv('Snail Kite Gridded Data_larger_behav.csv', header = T, sep = ',')
dat[dat$id==12,"tseg"] %>% unique()
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
library('MCMCpack')
library('Rcpp')
library(progress)
library(tidyverse)
library(lubridate)
library(rnaturalearth)
library(rnaturalearthdata)
library(sf)
source('LDA_behavior_function.R')
source('gibbs sampler.R')
source('helper functions.R')
sourceCpp('aux1.cpp')
############################
#### Load and Prep Data ####
############################
#get data
dat<- read.csv('Snail Kite Gridded Data_larger_behav.csv', header = T, sep = ',')
dat$date<- dat$date %>% as_datetime()
dat.list<- df.to.list(dat)
obs<- get.summary.stats_behav(dat)
#prepare for Gibbs sampler
ngibbs=1000
nburn=ngibbs/2
ind1=grep('y1',colnames(obs))
ind2=grep('y2',colnames(obs))
nmaxclust=max(length(ind1),length(ind2))-1  #max possible is 1 fewer than largest number of bins
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
library('MCMCpack')
library('Rcpp')
library(progress)
library(tidyverse)
library(lubridate)
library(rnaturalearth)
library(rnaturalearthdata)
library(sf)
source('LDA_behavior_function.R')
source('gibbs sampler.R')
source('helper functions.R')
sourceCpp('aux1.cpp')
############################
#### Load and Prep Data ####
############################
#get data
dat<- read.csv('Snail Kite Gridded Data_larger_behav.csv', header = T, sep = ',')
dat$date<- dat$date %>% as_datetime()
dat.list<- df.to.list(dat)
obs<- get.summary.stats_behav(dat)
#prepare for Gibbs sampler
ngibbs=1000
nburn=ngibbs/2
ind1=grep('y1',colnames(obs))
ind2=grep('y2',colnames(obs))
nmaxclust=max(length(ind1),length(ind2))-1  #max possible is 1 fewer than largest number of bins
set.seed(2)
#####################################################
#### Run Gibbs Sampler on All IDs Simultaneously ####
#####################################################
res=LDA_behavior_gibbs(dat=obs,gamma1=gamma1,alpha=alpha,
ngibbs=ngibbs,nmaxclust=nmaxclust,
nburn=nburn)
#Check traceplot of log marginal likelihood
plot(res$loglikel,type='l')
#Extract and plots proportions of behaviors per time segment
theta.post<- res$theta[(nburn+1):ngibbs,]
theta.estim<- theta.post %>% apply(2, mean) %>% matrix(nrow(obs), nmaxclust) #calc mean of posterior
boxplot(theta.estim)
#Determine proportion of behaviors (across all time segments)
#Possibly set threshold below which behaviors are excluded
round(apply(theta.estim, 2, sum)/nrow(theta.estim), digits = 3)
boxplot(theta.estim, xlab = "Behavior", ylab = "Probability of Occurrence")
#Check traceplot of log marginal likelihood
plot(res$loglikel,type='l', xlab = "Observations", ylab = "Log Marginal Likelihood")
#Determine proportion of behaviors (across all time segments)
#Possibly set threshold below which behaviors are excluded
round(apply(theta.estim, 2, sum)/nrow(theta.estim), digits = 3)
round(apply(theta.estim, 2, sum)/nrow(theta.estim), digits = 3)[1:3] %>% sum()
#lines
ggplot(theta.estim.long %>% filter(id == 1 | id == 12 | id == 19 | id == 27)) +
geom_path(aes(x=time1, y=prop, color = behavior)) +
labs(x = "\nObservation", y = "State Probability\n") +
scale_color_viridis_d("Behavior", direction = -1) +
theme_bw() +
theme(axis.title = element_text(size = 16), axis.text.y = element_text(size = 14),
axis.text.x.bottom = element_text(size = 12),
strip.text = element_text(size = 14, face = "bold"),
panel.grid = element_blank()) +
facet_wrap(~id, scales = "free_x")
ind<- which(dat2 %>% filter(id == 1 | id == 12 | id == 19 | id == 27))
behav.res<- get_behav_hist(res)
theta.estim<- data.frame(id = obs$id, tseg = obs$tseg, theta.estim)
names(theta.estim)<- c("id", "tseg", 1:nmaxclust)  #define behaviors
nobs<- data.frame(id = obs$id, tseg = obs$tseg, n = apply(obs[,11:16], 1, sum)) #calc obs per tseg
#Create augmented matrix by replicating rows (tsegs) according to obs per tseg
theta.estim2<- aug_behav_df(dat = dat, theta.estim = theta.estim, nobs = nobs)
#Change into long format
theta.estim.long<- theta.estim2 %>% gather(key, value, -id, -tseg, -time1, -date)
theta.estim.long$date<- theta.estim.long$date %>% as_datetime()
names(theta.estim.long)[5:6]<- c("behavior","prop")
#Add cluster assignments to original data; one column for dominant behavior and another for prop/prob to use for alpha of points
dat2<- assign_behav(dat.list = dat.list, theta.estim2 = theta.estim2)
ind<- which(dat2[dat2$id == 1 | dat2$id == 12 | dat2$id == 19 | dat2$id == 27,])
samp<- dat2[dat2$id == 1 | dat2$id == 12 | dat2$id == 19 | dat2$id == 27,]
ggplot() +
geom_sf(data = fl) +
coord_sf(xlim = c(min(dat$x-120000), max(dat$x+40000)),
ylim = c(min(dat$y-20000), max(dat$y+20000)), expand = FALSE) +
geom_path(data = samp, aes(x=x, y=y), color="gray60", size=0.25) +
geom_point(data = samp, aes(x, y, fill=behav), size=2.5, pch=21, alpha=samp$prop) +
scale_fill_viridis_d("Behavior", direction = -1) +
labs(x = "Longitude", y = "Latitude") +
theme_bw() +
theme(axis.title = element_text(size = 16),
strip.text = element_text(size = 14, face = "bold"),
panel.grid = element_blank()) +
guides(fill = guide_legend(label.theme = element_text(size = 12),
title.theme = element_text(size = 14))) +
facet_wrap(~id)
#load map data
usa <- ne_states(country = "United States of America", returnclass = "sf")
fl<- usa %>% filter(name == "Florida")
fl<- st_transform(fl, crs = "+init=epsg:32617") #change projection to UTM 17N
ggplot() +
geom_sf(data = fl) +
coord_sf(xlim = c(min(dat$x-120000), max(dat$x+40000)),
ylim = c(min(dat$y-20000), max(dat$y+20000)), expand = FALSE) +
geom_path(data = samp, aes(x=x, y=y), color="gray60", size=0.25) +
geom_point(data = samp, aes(x, y, fill=behav), size=2.5, pch=21, alpha=samp$prop) +
scale_fill_viridis_d("Behavior", direction = -1) +
labs(x = "Longitude", y = "Latitude") +
theme_bw() +
theme(axis.title = element_text(size = 16),
strip.text = element_text(size = 14, face = "bold"),
panel.grid = element_blank()) +
guides(fill = guide_legend(label.theme = element_text(size = 12),
title.theme = element_text(size = 14))) +
facet_wrap(~id)
set.seed(2)
library('MCMCpack')
library('Rcpp')
library(progress)
library(tidyverse)
library(lubridate)
library(rnaturalearth)
library(rnaturalearthdata)
library(sf)
source('LDA_behavior_function.R')
source('gibbs sampler.R')
source('helper functions.R')
sourceCpp('aux1.cpp')
dat<- read.csv('Snail Kite Gridded Data_larger_behav.csv', header = T, sep = ',')
dat<- dat %>% filter(id != 9 & id != 10.2 & id != 13  & id != 17)
dat$date<- dat$date %>% as_datetime()
dat.list<- df.to.list(dat)
obs<- get.summary.stats_behav(dat)
#prepare for Gibbs sampler
ngibbs=1000
nburn=ngibbs/2
ind1=grep('y1',colnames(obs))
ind2=grep('y2',colnames(obs))
nmaxclust=max(length(ind1),length(ind2))-1  #max possible is 1 fewer than largest number of bins
res=LDA_behavior_gibbs(dat=obs,gamma1=gamma1,alpha=alpha,
ngibbs=ngibbs,nmaxclust=nmaxclust,
nburn=nburn)
#Check traceplot of log marginal likelihood
plot(res$loglikel,type='l')
#Extract and plots proportions of behaviors per time segment
theta.post<- res$theta[(nburn+1):ngibbs,]
theta.estim<- theta.post %>% apply(2, mean) %>% matrix(nrow(obs), nmaxclust) #calc mean of posterior
# png("Boxplot of behavior probs.png", width = 7, height = 5, units = "in", res = 300)
boxplot(theta.estim, xlab="Behavior", ylab="Probability of Behavior Occurrence")
#Determine proportion of behaviors (across all time segments)
#Possibly set threshold below which behaviors are excluded
round(apply(theta.estim, 2, sum)/nrow(theta.estim), digits = 3)
#Determine proportion of behaviors (across all time segments)
#Possibly set threshold below which behaviors are excluded
round(apply(theta.estim, 2, sum)/nrow(theta.estim), digits = 3)[1:3] %>% sum()
behav.res<- get_behav_hist(res)
behav.res<- behav.res[behav.res$behav <=3,]  #only select the top 3 behaviors
#Plot histograms of frequency data; order color scale from slow to fast
ggplot(behav.res, aes(x = bin, y = count, fill = behav)) +
geom_bar(stat = 'identity') +
labs(x = "\nBin", y = "Frequency\n") +
theme_bw() +
theme(axis.title = element_text(size = 16), axis.text.y = element_text(size = 14),
axis.text.x.bottom = element_text(size = 12),
strip.text = element_text(size = 14), strip.text.x = element_text(face = "bold")) +
scale_fill_manual(values = viridis(n=3)[c(2,1,3)], guide = F) +
facet_grid(param ~ behav, scales = "free_y")
library(viridis)
#Plot histograms of frequency data; order color scale from slow to fast
ggplot(behav.res, aes(x = bin, y = count, fill = behav)) +
geom_bar(stat = 'identity') +
labs(x = "\nBin", y = "Frequency\n") +
theme_bw() +
theme(axis.title = element_text(size = 16), axis.text.y = element_text(size = 14),
axis.text.x.bottom = element_text(size = 12),
strip.text = element_text(size = 14), strip.text.x = element_text(face = "bold")) +
scale_fill_manual(values = viridis(n=3)[c(2,1,3)], guide = F) +
facet_grid(param ~ behav, scales = "free_y")
behav.res[[1]] %>% str()
View(behav.res)
str(behav.res)
#Plot histograms of frequency data; order color scale from slow to fast
ggplot(behav.res, aes(x = bin, y = count, fill = factor(behav))) +
geom_bar(stat = 'identity') +
labs(x = "\nBin", y = "Frequency\n") +
theme_bw() +
theme(axis.title = element_text(size = 16), axis.text.y = element_text(size = 14),
axis.text.x.bottom = element_text(size = 12),
strip.text = element_text(size = 14), strip.text.x = element_text(face = "bold")) +
scale_fill_manual(values = viridis(n=3)[c(2,1,3)], guide = F) +
facet_grid(param ~ behav, scales = "free_y")
#Plot histograms of proportion data; order color scale from slow to fast
ggplot(behav.res, aes(x = bin, y = prop, fill = as.factor(behav))) +
geom_bar(stat = 'identity') +
labs(x = "\nBin", y = "Proportion\n") +
theme_bw() +
theme(axis.title = element_text(size = 16), axis.text.y = element_text(size = 14),
axis.text.x.bottom = element_text(size = 12),
strip.text = element_text(size = 14), strip.text.x = element_text(face = "bold")) +
scale_fill_manual(values = viridis(n=3)[c(2,1,3)], guide = F) +
facet_grid(param ~ behav, scales = "fixed")
theta.estim<- apply(theta.estim[,1:3], 1, function(x) x/sum(x)) %>% t()  #normalize probs for only first 3 behaviors being used
theta.estim<- data.frame(id = obs$id, tseg = obs$tseg, theta.estim)
names(theta.estim)<- c("id", "tseg", "ARS","Transit","Resting")  #define behaviors
nobs<- data.frame(id = obs$id, tseg = obs$tseg, n = apply(obs[,11:16], 1, sum)) #calc obs per tseg using SL bins (more reliable than TA)
#Create augmented matrix by replicating rows (tsegs) according to obs per tseg
theta.estim2<- aug_behav_df(dat = dat, theta.estim = theta.estim, nobs = nobs)
#Change into long format
theta.estim.long<- theta.estim2 %>% gather(key, value, -id, -tseg, -time1, -date)
theta.estim.long$date<- theta.estim.long$date %>% as_datetime()
names(theta.estim.long)[5:6]<- c("behavior","prop")
theta.estim.long$behavior<- factor(theta.estim.long$behavior, levels = c("Resting","ARS","Transit"))
#stacked area
ggplot(theta.estim.long) +
geom_area(aes(x=time1, y=prop, fill = behavior), color = "black", size = 0.25,
position = "fill") +
labs(x = "\nObservation", y = "State Probability\n") +
scale_fill_viridis_d("Behavior", direction = -1) +
theme_bw() +
theme(axis.title = element_text(size = 16), axis.text.y = element_text(size = 14),
axis.text.x.bottom = element_text(size = 12),
strip.text = element_text(size = 14, face = "bold"),
panel.grid = element_blank()) +
facet_wrap(~id, scales = "free_x")
#stacked area
ggplot(theta.estim.long %>% filter(id==1)) +
geom_area(aes(x=time1, y=prop, fill = behavior), color = "black", size = 0.25,
position = "fill") +
labs(x = "\nObservation", y = "State Probability\n") +
scale_fill_viridis_d("Behavior", direction = -1) +
theme_bw() +
theme(axis.title = element_text(size = 16), axis.text.y = element_text(size = 14),
axis.text.x.bottom = element_text(size = 12),
strip.text = element_text(size = 14, face = "bold"),
panel.grid = element_blank()) +
facet_wrap(~id, scales = "free_x")
ggplot(theta.estim.long %>% filter(id==1)) +
geom_area(aes(x=time1, y=prop, fill = behavior), color = "black", size = 0.25,
position = "fill") +
labs(x = "\nObservation", y = "Proportion of Behavior\n") +
scale_fill_viridis_d("Behavior", direction = -1) +
theme_bw() +
theme(axis.title = element_text(size = 16), axis.text.y = element_text(size = 14),
axis.text.x.bottom = element_text(size = 12),
strip.text = element_text(size = 14, face = "bold"),
panel.grid = element_blank())
ggsave("Behavior area plot obs.png", width = 7, height = 5, units = "in", dpi = 300)
#Window of peak breeding (March 1 - June 30)
breed<- data.frame(xmin = as_datetime(c("2016-03-01 00:00:00","2017-03-01 00:00:00",
"2018-03-01 00:00:00","2019-03-01 00:00:00")),
xmax = as_datetime(c("2016-06-30 23:59:59","2017-06-30 23:59:59",
"2018-06-30 23:59:59","2019-06-30 23:59:59")),
ymin = -Inf, ymax = Inf)
ggplot(theta.estim.long %>% filter(id==1)) +
geom_area(aes(x=date, y=prop, fill = behavior), color = "black", size = 0.25,
position = "fill") +
geom_rect(data = breed, aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax),
fill = "grey", alpha = 0.25) +
labs(x = "\nTime", y = "State Probability\n") +
scale_fill_viridis_d("Behavior", direction = -1) +
theme_bw() +
theme(axis.title = element_text(size = 16), axis.text.y = element_text(size = 14),
axis.text.x.bottom = element_text(size = 12),
strip.text = element_text(size = 14, face = "bold"),
panel.grid = element_blank())
ggplot(theta.estim.long %>% filter(id==1)) +
geom_area(aes(x=date, y=prop, fill = behavior), color = "black", size = 0.25,
position = "fill") +
geom_rect(data = breed, aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax),
fill = "grey", alpha = 0.25) +
labs(x = "\nTime", y = "Proportion of Behavior\n") +
scale_fill_viridis_d("Behavior", direction = -1) +
theme_bw() +
theme(axis.title = element_text(size = 16), axis.text.y = element_text(size = 14),
axis.text.x.bottom = element_text(size = 12),
strip.text = element_text(size = 14, face = "bold"),
panel.grid = element_blank())
ggsave("Behavior area plot time.png", width = 7, height = 5, units = "in", dpi = 300)
#Add cluster assignments to original data; one column for dominant behavior and another for prop/prob to use for alpha of points
dat2<- assign_behav(dat.list = dat.list, theta.estim2 = theta.estim2)
dat2$behav<- factor(dat2$behav, levels = c("Resting","ARS","Transit"))
#load map data
usa <- ne_states(country = "United States of America", returnclass = "sf")
fl<- usa %>% filter(name == "Florida")
fl<- st_transform(fl, crs = "+init=epsg:32617") #change projection to UTM 17N
library(tidyverse)
require(tidyverse)
allmypackages <- as.data.frame(installed.packages())
allmypackages <- allmypackages %>%
filter(Priority != "base" | is.na(Priority)) %>%
select(-c(Enhances:MD5sum, LinkingTo:Suggests)) %>%
droplevels()
allmypackages <- as.data.frame(installed.packages())
View(allmypackages)
allmypackages <- allmypackages %>%
filter(Priority != "base" | is.na(Priority)) %>%
select(-c(Enhances:MD5sum, LinkingTo:Suggests)) %>%
droplevels()
str(allmypackages)
package_source <- function(pkg){
x <- as.character(packageDescription(pkg)$Repository)
if (length(x)==0) {
y <- as.character(packageDescription(pkg)$GithubRepo)
z <- as.character(packageDescription(pkg)$GithubUsername)
if (length(y)==0) {
return("Other")
} else {
return(str_c("GitHub repo = ", z, "/", y))
}
} else {
return(x)
}
}
# show the first 60 as an example
head(sapply(allmypackages$Package, package_source), 60)
allmypackages$whereat <- sapply(allmypackages$Package, package_source)
str(allmypackages)
table(allmypackages$whereat)
allmypackages %>%
filter(whereat == "Other") %>%
select(Package, Version)
setwd("~/Documents/Misc R Code")
write.csv(allmypackages, "mypackagelistJan2020.csv")
install.packages("tidyverse")
library(tidyverse)
setwd("~/Documents/Misc R Code")
oldpackages <- read.csv("mypackagelistJan2019.csv")
oldpackages <- read.csv("mypackagelistJan2020.csv")
allmypackages <- as.data.frame(installed.packages())
allmypackages <- allmypackages %>%
filter(Priority != "base" | is.na(Priority)) %>%
select(-c(Enhances:MD5sum, LinkingTo:Suggests))
thediff <- anti_join(oldpackages,allmypackages, by = "Package")
thediff <- droplevels(thediff)
thediff %>%
filter(whereat == "CRAN") %>%
pull(Package) %>%
as.character
#install these packages
thediff %>%
filter(whereat == "CRAN") %>%
pull(Package) %>%
as.character %>%
install.packages
install.packages('rpg')
install.packages("brew")
install.packages('rpg')
install.packages('gsl')
install.packages('ctmm')
install.packages('rpanel')
install.packages('stpp')
#check packages installed via Github
thediff %>%
filter(str_detect(whereat, "GitHub repo")) %>%
select(Package, Version, NeedsCompilation, whereat)
devtools::install_github("NMML/crawl")
devtools::install_github("JesJehle/earthEngineGrabR")
devtools::install_github("samclifford/mgcv.helper")
devtools::install_github("jmlondon/ptolemy")
devtools::install_github("rmendels/rerddapXtracto")
devtools::install_github("ropensci/rnaturalearthhires")
devtools::install_github("vqv/ggbiplot")
devtools::install_github("cmartin/ggConvexHull")
devtools::install_github("gavinsimpson/ggvegan")
devtools::install_github("andrewljackson/SIBER")
allmypackages <- as.data.frame(installed.packages())
allmypackages <- allmypackages %>%
filter(Priority != "base" | is.na(Priority)) %>%
select(-c(Enhances:MD5sum, LinkingTo:Suggests)) %>%
droplevels()
str(allmypackages)
set.seed(2)
library('MCMCpack')
library('Rcpp')
library(progress)
library(tidyverse)
library(lubridate)
library(rnaturalearth)
library(rnaturalearthdata)
library(sf)
library(viridis)
source('LDA_behavior_function.R')
source('gibbs sampler.R')
source('helper functions.R')
sourceCpp('aux1.cpp')
dat<- read.csv('Snail Kite Gridded Data_larger_behav.csv', header = T, sep = ',')
dat$date<- dat$date %>% as_datetime()
dat.list<- df.to.list(dat)  #for later behavioral assignment
obs<- get.summary.stats_behav(dat)  #to run Gibbs sampler on
#prepare for Gibbs sampler
ngibbs=1000
nburn=ngibbs/2
ind1=grep('y1',colnames(obs))
ind2=grep('y2',colnames(obs))
nmaxclust=max(length(ind1),length(ind2))-1  #max possible is 1 fewer than largest number of bins
res=LDA_behavior_gibbs(dat=obs, gamma1=gamma1, alpha=alpha,
ngibbs=ngibbs, nmaxclust=nmaxclust,
nburn=nburn)
#Check traceplot of log marginal likelihood
plot(res$loglikel, type='l')
#Extract and plot proportions of behaviors per time segment
theta.post<- res$theta[(nburn+1):ngibbs,]  #extract samples from posterior
theta.estim<- theta.post %>% apply(2, mean) %>% matrix(nrow(obs), nmaxclust) #calc mean of posterior
boxplot(theta.estim, xlab="Behavior", ylab="Probability of Behavior Occurrence")
#Determine proportion of behaviors (across all time segments)
#Possibly set threshold below which behaviors are excluded
round(apply(theta.estim, 2, sum)/nrow(theta.estim), digits = 3)
#Determine proportion of behaviors (across all time segments)
#Possibly set threshold below which behaviors are excluded
round(apply(theta.estim, 2, sum)/nrow(theta.estim), digits = 3)[1:3] %>% sum()
behav.res<- get_behav_hist(res)
#Plot histograms of frequency data; order color scale from slow to fast
ggplot(behav.res, aes(x = bin, y = count, fill = as.factor(behav))) +
geom_bar(stat = 'identity') +
labs(x = "\nBin", y = "Frequency\n") +
theme_bw() +
theme(axis.title = element_text(size = 16), axis.text.y = element_text(size = 14),
axis.text.x.bottom = element_text(size = 12),
strip.text = element_text(size = 14), strip.text.x = element_text(face = "bold")) +
scale_fill_manual(values = viridis(n=3)[c(2,1,3)], guide = F) +
facet_grid(param ~ behav, scales = "free_y")
#Plot histograms of frequency data; order color scale from slow to fast
ggplot(behav.res, aes(x = bin, y = count, fill = as.factor(behav))) +
geom_bar(stat = 'identity') +
labs(x = "\nBin", y = "Frequency\n") +
theme_bw() +
theme(axis.title = element_text(size = 16), axis.text.y = element_text(size = 14),
axis.text.x.bottom = element_text(size = 12),
strip.text = element_text(size = 14), strip.text.x = element_text(face = "bold")) +
facet_grid(param ~ behav, scales = "free_y")
#Plot histograms of frequency data; order color scale from slow to fast
ggplot(behav.res, aes(x = bin, y = prop, fill = as.factor(behav))) +
geom_bar(stat = 'identity') +
labs(x = "\nBin", y = "Proportion\n") +
theme_bw() +
theme(axis.title = element_text(size = 16), axis.text.y = element_text(size = 14),
axis.text.x.bottom = element_text(size = 12),
strip.text = element_text(size = 14), strip.text.x = element_text(face = "bold")) +
facet_grid(param ~ behav, scales = "free_y")
behav.res<- behav.res[behav.res$behav <=3,]  #only select the top 3 behaviors
#Plot histograms of frequency data; order color scale from slow to fast
ggplot(behav.res, aes(x = bin, y = count, fill = as.factor(behav))) +
geom_bar(stat = 'identity') +
labs(x = "\nBin", y = "Frequency\n") +
theme_bw() +
theme(axis.title = element_text(size = 16), axis.text.y = element_text(size = 14),
axis.text.x.bottom = element_text(size = 12),
strip.text = element_text(size = 14), strip.text.x = element_text(face = "bold")) +
scale_fill_manual(values = viridis(n=3)[c(2,1,3)], guide = F) +
facet_grid(param ~ behav, scales = "free_y")
#Plot histograms of proportion data; order color scale from slow to fast
ggplot(behav.res, aes(x = bin, y = prop, fill = as.factor(behav))) +
geom_bar(stat = 'identity') +
labs(x = "\nBin", y = "Proportion\n") +
theme_bw() +
theme(axis.title = element_text(size = 16), axis.text.y = element_text(size = 14),
axis.text.x.bottom = element_text(size = 12),
strip.text = element_text(size = 14), strip.text.x = element_text(face = "bold")) +
scale_fill_manual(values = viridis(n=3)[c(2,1,3)], guide = F) +
facet_grid(param ~ behav, scales = "fixed")
